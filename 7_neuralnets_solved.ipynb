{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to neural networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session we will start with a simple toy implementation of a neural network and apply it to the XOR problem. In the second part we will learn how to use the [Keras toolkit](https://keras.io/) to define, train and use a practical neural network model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR\n",
    "\n",
    "Let's start with the [XOR problem](https://en.wikipedia.org/wiki/XOR_gate). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "%pylab inline --no-import-all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7.1\n",
    "Define the function `xor`, which which takes a Nx2 array, where each row is an input to the logical XOR. It outputs an array of size N with the corresponding outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xor(X):\n",
    "    #.........\n",
    "    return (X.sum(axis=1) == 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "X = numpy.array([[0, 0],      # FALSE\n",
    "                 [0, 1],      # TRUE\n",
    "                 [1, 0],      # TRUE\n",
    "                 [1, 1]])     # FALSE\n",
    "y = xor(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fa1563cf860>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa158453ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pylab.scatter(X[:,0], X[:,1], c=y, s=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network\n",
    "We can define a simple two layer neural network by hand which solves the XOR classification problem. The network has parameters $\\mathbf{W}$ and $\\mathbf{U}$, and computes the following:\n",
    "\n",
    "$$Y = \\sigma(U(\\sigma(WX^T))$$\n",
    "\n",
    "Where $\\mathbf{X}$ is the input array, with shape Nx2, $\\mathbf{W}$ is a 2x2 matrix, and $\\mathbf{U}$ is a 1x2 matrix. The result is a 1xN matrix (i.e. a single row vector) of XOR values.\n",
    "\n",
    "### Exercise 7.2\n",
    "\n",
    "Define function `sigma` which returns one if the input is greater than or equal to 0.5, and zero otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(X):\n",
    "    #...............\n",
    "    return (X >= 0.5).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.95125363  0.83903522]\n",
      " [ 0.75394668  0.28882588]\n",
      " [ 0.80585408  0.58343813]]\n",
      "[[ 1.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "z = numpy.random.uniform(0,1,(3,2))\n",
    "print(z)\n",
    "print(sigma(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7.3\n",
    "\n",
    "Define function `nnet` which takes the weight matrices W and U, and the input X, and returns the result Y computed according to the formula above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnet(W,U,X):\n",
    "    #..........................................\n",
    "    Z = sigma(numpy.dot(W,numpy.transpose(X)))\n",
    "    return sigma(numpy.dot(U,Z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = numpy.array([[1,-1],\n",
    "                 [-1,1]])\n",
    "U = numpy.array([1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check what it outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0]\n",
      "[ 0.  1.  1.  0.]\n"
     ]
    }
   ],
   "source": [
    "y_pred = nnet(W, U, X)\n",
    "print(y)\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot the outputs as a function of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], <a list of 0 Text yticklabel objects>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa156387240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a grid of points for plotting\n",
    "shape=(20,20)\n",
    "grid = numpy.array([ [i,j] for i in numpy.linspace(0,1,shape[0]) \n",
    "                               for j in numpy.linspace(0,1,shape[1]) ])\n",
    "# Apply the neural net to all the points\n",
    "y_pred = nnet(W, U, grid)\n",
    "pylab.pcolor(y_pred.reshape((20,20)))\n",
    "pylab.colorbar()\n",
    "pylab.xticks([])\n",
    "pylab.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training XOR NN with Keras\n",
    "\n",
    "We'll now learn how to build a simple neural network in Keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "# Add two hidden layers with 4 hidden units each, and the tanh activation.\n",
    "\n",
    "model.add(Dense(4, input_dim=2, activation='tanh'))\n",
    "model.add(Dense(4, activation='tanh'))\n",
    "\n",
    "# The final layer is the output layer with an inverse logit activation function.\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Use the Adam optimizer. Adam works similar to regular SGD, \n",
    "# but with some important improvements: https://arxiv.org/abs/1412.6980\n",
    "optimizer = Adam(lr=0.02)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train the model, specifying number of epochs, size of the minibatch, and whether to print extra information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.7507\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7023\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6902\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6845\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6846\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6737\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6748\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6676\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.6652\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6616\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6590\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.6523\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6462\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6370\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6364\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6289\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6214\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6102\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5960\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5864\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5769\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5675\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5581\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5439\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5380\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5208\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5130\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5007\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4919\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4854\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4684\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4539\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4468\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4337\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4201\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4007\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3892\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3689\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3518\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3311\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3275\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3081\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.2858\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2622\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2432\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.2240\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2053\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1883\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.1698\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1570\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1418\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1284\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1171\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1050\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0949\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0854\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0792\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0729\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0668\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0598\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0560\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0504\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0468\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0440\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0403\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0377\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0358\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0330\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0309\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0291\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0276\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0260\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0246\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0235\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0223\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0206\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0194\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0185\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0177\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0170\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0163\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0145\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0140\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0136\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0131\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0127\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0123\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0119\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0115\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0112\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0108\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0106\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0102\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0099\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0097\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0094\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa145b7ad30>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=100, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x1          x2          F(x1, x2)\n",
      "[[ 0.          0.          0.00521935]\n",
      " [ 0.          1.          0.99282151]\n",
      " [ 1.          0.          0.99291104]\n",
      " [ 1.          1.          0.01610738]]\n"
     ]
    }
   ],
   "source": [
    "print(\"   x1          x2          F(x1, x2)\")\n",
    "print(np.hstack([X, model.predict(X)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], <a list of 0 Text yticklabel objects>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa13c7bff60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply the neural net to all the points\n",
    "y_pred = model.predict(grid)\n",
    "pylab.pcolor(y_pred.reshape((20,20)))\n",
    "pylab.colorbar()\n",
    "pylab.xticks([])\n",
    "pylab.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression with NN on iris\n",
    "\n",
    "We will now define and train a neural network model for regression on the iris data.\n",
    "\n",
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "# Inputs\n",
    "X = numpy.array(data.data[:,0:3], dtype='float32')\n",
    "# Output\n",
    "y = numpy.array(data.data[:,3], dtype='float32')\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=1/3, random_state=999)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7.4\n",
    "\n",
    "\n",
    "Define a multilayer perceptron with the following specifications:\n",
    "- Hidden layer 1: size 16, activation: tanh\n",
    "- Hidden layer 2: size 16, activation: tanh\n",
    "- Output layer: size 1, activation: linear\n",
    "\n",
    "Compile it using the following specifications:\n",
    "- optimizer: Adam\n",
    "- loss: mean squared error\n",
    "\n",
    "Train the network, and try to find a good value of learning rate by monitoring the loss.\n",
    "\n",
    "Compute mean absolute error and r-squared the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 1s - loss: 0.4570\n",
      "Epoch 2/20\n",
      " - 0s - loss: 0.3616\n",
      "Epoch 3/20\n",
      " - 0s - loss: 0.2963\n",
      "Epoch 4/20\n",
      " - 0s - loss: 0.2395\n",
      "Epoch 5/20\n",
      " - 0s - loss: 0.1939\n",
      "Epoch 6/20\n",
      " - 0s - loss: 0.1559\n",
      "Epoch 7/20\n",
      " - 0s - loss: 0.1271\n",
      "Epoch 8/20\n",
      " - 0s - loss: 0.1047\n",
      "Epoch 9/20\n",
      " - 0s - loss: 0.0890\n",
      "Epoch 10/20\n",
      " - 0s - loss: 0.0762\n",
      "Epoch 11/20\n",
      " - 0s - loss: 0.0682\n",
      "Epoch 12/20\n",
      " - 0s - loss: 0.0627\n",
      "Epoch 13/20\n",
      " - 0s - loss: 0.0581\n",
      "Epoch 14/20\n",
      " - 0s - loss: 0.0565\n",
      "Epoch 15/20\n",
      " - 0s - loss: 0.0545\n",
      "Epoch 16/20\n",
      " - 0s - loss: 0.0536\n",
      "Epoch 17/20\n",
      " - 0s - loss: 0.0519\n",
      "Epoch 18/20\n",
      " - 0s - loss: 0.0507\n",
      "Epoch 19/20\n",
      " - 0s - loss: 0.0500\n",
      "Epoch 20/20\n",
      " - 0s - loss: 0.0496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa118f71438>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#..................................\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=3, activation='tanh'))\n",
    "model.add(Dense(16, activation='tanh'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.181786\n",
      "0.900227223893\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "y_pred = model.predict(X_val)\n",
    "print(mean_absolute_error(y_val, y_pred))\n",
    "print(r2_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "Let's now do classification. The target is a categorical vector. It will need to be transformed to an array of dummies. This transform is also called on-hot encoding.\n",
    "This can be done manually, but sklearn.preprocessing has some utilities that make it simple:\n",
    "- OneHotEncoder\n",
    "- LabelBinarizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# Inputs\n",
    "X = numpy.array(data.data, dtype='float32')\n",
    "# Output\n",
    "y = numpy.array(data.target, dtype='int32')\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=1/3, random_state=999)\n",
    "\n",
    "# One-hot Indicator array for classes\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "onehot = LabelBinarizer()\n",
    "Y_train = onehot.fit_transform(y_train)\n",
    "Y_val   = onehot.transform(y_val)\n",
    "\n",
    "print(Y_train[:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7.5\n",
    "\n",
    "Define a multilayer perceptron with the following specifications:\n",
    "- Hidden layer 1: size 16, activation: tanh\n",
    "- Hidden layer 2: size 16, activation: tanh\n",
    "- Output layer: size 3, activation: softmax\n",
    "\n",
    "NB: softmax is a generalization of inverse logit to more than 2 classes. It converts class scores to class probabilities, while making sure than they sum up to 1:\n",
    "\n",
    "```\n",
    "def softmax(x):\n",
    "    z = numpy.exp(x)\n",
    "    return z/numpy.sum(z)\n",
    "```\n",
    "\n",
    "Compile it using the following specifications:\n",
    "- optimizer: Adam\n",
    "- loss: categorical_crossentropy\n",
    "\n",
    "Train the network, and try to find a good value of learning rate by monitoring the loss.\n",
    "Use the method `.predict_classes` to predict the targets on validation data.\n",
    "Compute the classification accuracy on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 1s - loss: 0.9960\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.6772\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.4705\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.3259\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.2696\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.2153\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.1671\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.1619\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.1375\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.1181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa118c4a6a0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#.....................................\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=4, activation='tanh'))\n",
    "model.add(Dense(16, activation='tanh'))\n",
    "model.add(Dense(3, activation='softmax')) # We need to have as many units as classes, \n",
    "                                                             # and softmax activation\n",
    "optimizer = Adam(lr=0.001)\n",
    "# For classification, the loss function should be categorical_crossentropy\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "model.fit(X_train, Y_train, epochs=10, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96\n"
     ]
    }
   ],
   "source": [
    "#.....................................\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = model.predict_classes(X_val, verbose=False)\n",
    "print(accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7.6\n",
    "\n",
    "\n",
    "Train a neural network classifier on the handwritten digits dataset. \n",
    "This dataset comes with scikit learn and can be accessed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAADfCAYAAADWQznrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAD2tJREFUeJzt3W2MXHd1x/HfSRw1JCa7Ni1RgTbrIChPxZuHV1SpbTVuSqrK69JEaSHYqJWtREGxBch+EeRNAGFLCGzx0Bop8poGIdlSbLeAQEmjtQpSC45sV0KEQLIOBGJBiL0kIXEhnL64YymNfc/dveuZ/z3e70daJdmTmXtm9t7f3pk5+7/m7gIA5HFB6QYAALNDcANAMgQ3ACRDcANAMgQ3ACRDcANAMgQ3ACSTOrjNbLGZ7TOz583sCTP7h9I9lWZmd5jZITM7ZWYTpfvpAjP7PTO7t7ePPGtmh83s3aX7Ks3M7jOzp8zsV2b2qJn9U+meusLM3mRmL5rZfaV7OZsFpRuYo89L+l9Jl0salfQ1Mzvq7t8r21ZRP5P0cUk3SHpV4V66YoGkn0haJunHkm6UtMfM/tTdj5VsrLBPSvpHdz9lZm+RNGlmh9394dKNdcDnJX23dBN10p5xm9mlkt4j6aPu/py7f0vSv0m6tWxnZbn7/e6+X9IvS/fSFe7+vLuPu/sxd/+du39V0pSka0r3VpK7f8/dT53+z97XGwu21Almdoukk5L+o3QvddIGt6Q3S3rJ3R992feOSnp7oX6QhJldrmr/mc+vzCRJZvYFM/u1pEckPSXp64VbKsrMLpN0j6QPle4lkjm4F0qafsX3piW9ukAvSMLMLpL0ZUm73f2R0v2U5u63qzpmrpN0v6RT8S3Oex+TdK+7/6R0I5HMwf2cpMte8b3LJD1boBckYGYXSPpXVZ+L3FG4nc5w95d6bzW+QdJtpfspxcxGJV0v6TOle2mS+cPJRyUtMLM3ufsPe99bKl7+4izMzCTdq+qD7Bvd/TeFW+qiBZrf73EvlzQi6cfV7qKFki40s7e5+9UF+zpD2jNud39e1Uu7e8zsUjP7M0mrVJ1RzVtmtsDMLpZ0oaqd7mIzy/wL+lz5Z0lvlfQ37v5C6WZKM7PXmtktZrbQzC40sxsk/b2kh0r3VtAXVf3iGu19/Yukr6ma0OqUtMHdc7uqkbefS/qKpNvm+SigJN0l6QVJmyW9r/fvdxXtqDAzu0LSelUH43Eze6739d7CrZXkqt4WeVLSCUmfkrTB3Q8U7aogd/+1ux8//aXq7dgX3f0XpXt7JeNCCgCQS/YzbgCYdwhuAEiG4AaAZAhuAEimX2NirT7x3Lt3b1jftGlTbW3lypW1ta1bt9bWFi1a1NxYPZvF/9uXT4GXL19eWzt58mRtbXx8vLY2NjY2h47KPyeTk5O1teixjY6OtrrPGej7c7Jt27awvnnz5trakiVLamsPP1y/3tQAjx2pT/tKdIysXbu2trZ///4+dCNphs8LZ9wAkAzBDQDJENwAkAzBDQDJENwAkAzBDQDJdGrVuGjcT5KmpqZqaydOnKitLV68uLa2Z8+ecJs33XRTWC9teHi4tnbw4MHaWtuRuS44cuRIWF+xYkVtbWhoqLZ27Nixti0NRDTS17Qf79y5s7a2fv362lo0Dnj99deH28xgYmKithaNh5bGGTcAJENwA0AyBDcAJENwA0AyBDcAJENwA0AyAx8HjMaLonE/SXrsscdqa1deeWVtLVo5MOpHKj8O2DT61nbVui6POjVpWplt6dKltbVo1PHuu+9u3dMgrFu3rrbWNEp7zTXX1Nai1QGzj/xFq/9J8Tjghg0bamtzGR0dGRlpfdvTOOMGgGQIbgBIhuAGgGQIbgBIhuAGgGQIbgBIhuAGgGQGPscdLb969dVXh7eNZrUj0QxrF2zfvr22Fl2NXZKmp6dbbTO6OnzXRfO1UjwnG9121apVbVsaiGj/f/zxx8PbRn8jEc1qR8frHK/yPhDRnLYUz2NHV3mP9qNoqWWp+ZieCc64ASAZghsAkiG4ASAZghsAkiG4ASAZghsAkunUOGC0/Gq/ttmFkaZotCgaSZLa99+03GVpUX/R+KTUvOxrnabRsS5rGpV95plnamvROGBUe/DBB8NtDurYin7eGzduDG+7Zs2aVtvcsWNHbW3Xrl2t7nM2OOMGgGQIbgBIhuAGgGQIbgBIhuAGgGQIbgBIZuDjgNGIUNMV1yPRyN+hQ4dqazfffHPrbWYWXT2+C1eAj1ZQi0axmuzbt6+21rSqW2bRcReN9a1fv762tm3btnCbW7dubW7sHIh+bkNDQ+Ftd+/eXVuLjpHI2NhYq9vNBmfcAJAMwQ0AyRDcAJAMwQ0AyRDcAJAMwQ0AyQx8HDBaxSwa25OkvXv3tqpFNm3a1Op26K9oVcTJycnwtkePHq2trV69urYWXSy4aZXGQYyARTZv3hzW214Q+IEHHqitdWWUNrrwddMqmNHIX3S/0aqCgxgr5YwbAJIhuAEgGYIbAJIhuAEgGYIbAJIhuAEgGYIbAJLp1Bx30zKR0cz1tddeW1uby3KxpTXNhEazxwcOHKitRbPQTTPLgxAtLdu03GZUj5aLjZ6vkZGRcJul57ibrqi+bt26VvcbzWrv3Lmz1X12SXR8TU9P19ZKHyOccQNAMgQ3ACRDcANAMgQ3ACRDcANAMgQ3ACRj7l66BwDALHDGDQDJENwAkAzBDQDJENwAkAzBDQDJENwAkAzBDQDJENwAkAzBDQDJENwAkAzBDQDJENwAkAzBDQDJENwAkAzBDQDJENwAkAzBDQDJENwAkAzBDQDJENwAkAzBDQDJENwAkAzBDQDJENwAkAzBDQDJENwAkAzBDQDJENwAkAzBDQDJENwAkAzBDQDJENwAkAzBDQDJENwAkAzBDQDJENwAkAzBDQDJENwAkAzBDQDJENwAkAzBDQDJENwAkAzBDQDJENwAkAzBDQDJENwAkEz64DazSTN70cye6339oHRPXWBmt5jZ983seTN7zMyuK91TKS/bN05/vWRmny3dV2lmNmJmXzezE2Z23Mw+Z2YLSvdVkpm91cweMrNpM/uRma0u3dPZpA/unjvcfWHv609KN1Oama2UtE3SByS9WtKfS3q8aFMFvWzfWCjpckkvSNpbuK0u+IKkn0v6Q0mjkpZJur1oRwX1fmkdkPRVSYslrZN0n5m9uWhjZ3G+BDf+v7sl3ePu/+Xuv3P3n7r7T0s31RF/pyqs/rN0Ix2wRNIed3/R3Y9L+oaktxfuqaS3SHqdpM+4+0vu/pCkb0u6tWxbZzpfgvuTZva0mX3bzJaXbqYkM7tQ0rWS/qD3Uu/J3kvgV5XurSPWSPqSu3vpRjpgh6RbzOwSM3u9pHerCu/5ymq+945BN9LkfAjuTZKulPR6SV+U9O9m9sayLRV1uaSLVJ1ZXqfqJfBVku4q2VQXmNkfq3o7YHfpXjrioKoz7F9JelLSIUn7i3ZU1iOqXo19xMwuMrO/VLW/XFK2rTOlD253/293f9bdT7n7blUvbW4s3VdBL/T++Vl3f8rdn5b0ac3v5+S090v6lrtPlW6kNDO7QNI3Jd0v6VJJvy9pkarPRuYld/+NpDFJfy3puKQPSdqj6pdap6QP7rNwnf0lz7zg7idU7Wi8FXCm94uz7dMWS/ojSZ/rnfT8UtIuzfNf8O7+P+6+zN1f4+43qHo1/53Sfb1S6uA2s2Ezu8HMLjazBWb2XlUTFN8s3VthuyR90Mxea2aLJG1Q9Un5vGVm71L1dhrTJJJ6r8SmJN3WO3aGVb3/f7RsZ2WZ2Tt7eXKJmX1Y1cTNROG2zpA6uFW9l/txSb+Q9LSkD0oac/f5Psv9MUnflfSopO9LOizpE0U7Km+NpPvd/dnSjXTI30r6K1XHz48k/VbSxqIdlXerpKdUvdf9F5JWuvupsi2dyfhwHQByyX7GDQDzDsENAMkQ3ACQDMENAMn0ayWwVp94Ll++PKyPjIzU1iYmJtpscq5mMy/el0+Bo+fs5MmTtbUjR470oRtJA3hOtm/fHtajx71/f/0fBh49Wj8JNzQ0FG7z2LFjtbXh4eG+PycbNmwI69HjXrt2bav7HR4ebuwrMNu/tWj1vIyNjYX1aF+ZnJxss8m5mtHzwhk3ACRDcANAMgQ3ACRDcANAMgQ3ACRDcANAMv1aq6TVnUbjfpL0xBNPtLlbXXHFFbW1aIxrBvo+5hWNcUnS6tX11zLdsmVLbW18fLxNOzNRfBwwMjo62up+o7ExqXF0rO/PSdMobdv9PDom5zgud87GAaPHtmTJklluZmaWLl1aW5vjqC3jgABwPiK4ASAZghsAkiG4ASAZghsAkiG4ASCZfq0O2ErTamPROGC0elvbFfRm0lO/zWVsr2lltKyaVsKLRM9nNFZWaKW4GYvGHKX2K2tG+3/Tc9I0oniuNB3DkWXLltXW+jgKOWeccQNAMgQ3ACRDcANAMgQ3ACRDcANAMgQ3ACRDcANAMp2a425a1jW6Cvf09HRtLZpxLT2n3aRpRjVaXrJptrfLojnZuczQtl0Stml53ehK6YPQtP2rrrqqttZwhfraWtPxOihz6SP6uUZ/BzGX2fFzgTNuAEiG4AaAZAhuAEiG4AaAZAhuAEiG4AaAZDo1Dtg0chWNgUVXVt64cWPblua0hOi50DR2FI1CRaNv0ahTF8a8oh6arqLddlww2v8GtURpW3MZTzt48GBtbWpqqrbWhf1EikcWo3FZSVq0aFFt7c4776ytRftgNF4pnZvnjTNuAEiG4AaAZAhuAEiG4AaAZAhuAEiG4AaAZDo1DtikHyNZTaM7pTWNDkWjXNGIWDQiefjw4XCbg1h1MHrcTWOjZlZb27dvX22t6yN/0QjaihUrwttu2bKlthYdA9HYaNPPoQvjgk2jo1G97X7eNELc9LzNBGfcAJAMwQ0AyRDcAJAMwQ0AyRDcAJAMwQ0AyXRqHLBpTCZaBWx8fLzVNqNxpy5oughsNNYXjWNFI2BNP4fSFyFuGrcaGhqqrXV95C8S/TyjxyzFz1m0L0QXGZ6YmAi32faYHKRoX46es+ixn4txvyaccQNAMgQ3ACRDcANAMgQ3ACRDcANAMgQ3ACRDcANAMp2a4266OveOHTta3e+aNWtqa12f622a445mcKNZ0+hxd322vWk/iR539LcAXRf13rQfR1czj2bAV61aVVtrmqfvgqYeo2Vdo2WRo31wEH/nwBk3ACRDcANAMgQ3ACRDcANAMgQ3ACRDcANAMubupXsAAMwCZ9wAkAzBDQDJENwAkAzBDQDJENwAkAzBDQDJENwAkAzBDQDJENwAkAzBDQDJENwAkAzBDQDJENwAkAzBDQDJENwAkAzBDQDJENwAkAzBDQDJENwAkAzBDQDJENwAkAzBDQDJENwAkMz/Abqb4kyxzkNOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa118c6cf60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "\n",
    "for index, (image, label) in enumerate(images_and_labels[:10]):\n",
    "    pylab.subplot(2, 5, index + 1)\n",
    "    pylab.axis('off')\n",
    "    pylab.imshow(image,cmap=plt.cm.gray_r)\n",
    "    pylab.title('%i' % label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The targets are in `digits.target` and the pixel values flattened into an array are in `digits.data`.\n",
    "\n",
    "Train a classifier on the first 1000 of the images, and evaluate on the rest. \n",
    "Before testing the neural network model, check the classification error rate of a logistic regression classifier as a baseline.\n",
    "\n",
    "\n",
    "Remember to convert the targets to the one-hot representation for training the neural network.\n",
    "\n",
    "Some things to try when training a neural network model for this dataset:\n",
    "\n",
    "- start with two or three hidden layers\n",
    "- use between 32 to 128 units in each layer\n",
    "- try different learning rates in the Adam optimizer (lr=0.001, lr=0.0001) and monitor the loss function\n",
    "- train for at least 100 epochs\n",
    "- try the `relu` activation function instead of `tanh`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0740276035132\n"
     ]
    }
   ],
   "source": [
    "# .....................\n",
    "X_train = digits.data[:1000,:]\n",
    "y_train = digits.target[:1000]\n",
    "X_val = digits.data[1000:,:]\n",
    "y_val = digits.target[1000:]\n",
    "\n",
    "onehot = LabelBinarizer()\n",
    "Y_train = onehot.fit_transform(y_train)\n",
    "Y_val   = onehot.transform(y_val)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "baseline = LogisticRegression()\n",
    "baseline.fit(X_train, y_train)\n",
    "print(1-accuracy_score(y_val, baseline.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa118096cf8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#.....................................\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='tanh'))\n",
    "model.add(Dense(64, activation='tanh'))\n",
    "model.add(Dense(Y_train.shape[1], activation='softmax')) # We need to have as many units as classes, \n",
    "                                                             # and softmax activation\n",
    "optimizer = Adam(lr=0.001)\n",
    "# For classification, the loss function should be categorical_crossentropy\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "model.fit(X_train, Y_train, epochs=100, batch_size=16, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0677540777917\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_val, verbose=0)\n",
    "print(1-accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
