{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression\n",
    "\n",
    "In this session we will develop a simple implementation of Logistic Regression trained with SDG. The goal is to develop the understanding of gradient descent, the logistic regression model and the practical use of numpy.\n",
    "\n",
    "First we'll load some toy data to use with our functions.  We'll make this into a binary problem by keeping only two species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "# skip rows with the label 2\n",
    "data = iris.data[iris.target != 2]\n",
    "target = iris.target[iris.target != 2]\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, target, \n",
    "                                                  test_size=1/3, random_state=123)\n",
    "\n",
    "\n",
    "# Z-score the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition\n",
    "\n",
    "\n",
    "We'll first define the interface of our model:\n",
    "\n",
    "- `predict` - compute predicted classes on new examples given a trained model\n",
    "- `predict_proba` - - compute class probabilities on new examples given a trained model\n",
    "- `fit` - train a model using features and labels from the training set\n",
    "\n",
    "as well some auxiliary functions.\n",
    "\n",
    "\n",
    "### Exercise 6.1\n",
    "\n",
    "Define function `inverse_logit`. The mathematical formulation is:\n",
    "$$\n",
    "\\mathrm{logit}^{-1}(z) = \\frac{1}{1+\\exp(-z)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_logit(z):\n",
    "    #..................................\n",
    "    return 1/(1+numpy.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.622459331202\n",
      "3.72007597602e-44\n",
      "0.5\n",
      "1.0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(inverse_logit(0.5))\n",
    "print(inverse_logit(-100))\n",
    "print(inverse_logit(0.0))\n",
    "print(inverse_logit(40.0))\n",
    "print(inverse_logit(40.0) == inverse_logit(100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Due to limited precision of floating point numbers, past a certain absolute value of the input, our function becomes a constant 1 or 0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.2 \n",
    "\n",
    "Define function `predict_proba`, with two arguments:\n",
    "\n",
    "- dictionary of model parameters `{'w':w,'b':b}`, where `w` is an numpy array of coefficients and `b` a scalar intercept\n",
    "- numpy array (matrix) of new the features of new examples `X`\n",
    "\n",
    "The function should return an array of probabilities of the positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(wb, X):\n",
    "    #...............................\n",
    "    return inverse_logit(X.dot(wb['w']) + wb['b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34, 4)\n",
      "(34,)\n",
      "[ 0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5\n",
      "  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5\n",
      "  0.5  0.5  0.5  0.5]\n"
     ]
    }
   ],
   "source": [
    "# Initial model parameters\n",
    "w = numpy.zeros((X_train.shape[1],))\n",
    "b = 0\n",
    "wb = {'w':w,'b':b}\n",
    "# Use this initial model for prediction\n",
    "p_pred = predict_proba(wb, X_val)\n",
    "print(X_val.shape)\n",
    "print(p_pred.shape)\n",
    "print(p_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.3\n",
    "Define function `predict` which takes the same input as `predict_proba` but returns the class labels (0 or 1) instead of probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(wb, X):\n",
    "    #.............................\n",
    "    return (predict_proba(wb, X) >= 0.5).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34, 4)\n",
      "(34,)\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(wb, X_val)\n",
    "print(X_val.shape)\n",
    "print(y_pred.shape)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model interface is complete.\n",
    "\n",
    "## Training\n",
    "We will now implement the interface of the SGD training algorithm:\n",
    "\n",
    "- `fit` which takes initial model parameters and trains it for one pass over the given training data\n",
    "\n",
    "We will start with an auxiliary function `update` which does a single step of SGD.\n",
    "\n",
    "\n",
    "### Exercise 6.5\n",
    "\n",
    "Define function `update` which is given a single training example, and first uses the `predict_proba` function to get the predicted probability of the positive class, and then updates the weights and the bias of\n",
    "the model depending on the difference between this probability and the actual target. \n",
    "\n",
    "The function is given these arguments:\n",
    "\n",
    "- `wb` - the model weights and bias (dictionary of model parameters `{'w':w,'b':b}`, where `w` is an numpy array of coefficients and `b` a scalar intercept)\n",
    "- `x`  - the feature vector of the training example\n",
    "- `y`  - the class label of the training example\n",
    "- `eta`- learning rate\n",
    "\n",
    "The update should change the given parameters by implementing the following operations:\n",
    "$$\n",
    "\\mathbf{w}_{new} = \\mathbf{w}_{old} + \\eta(y-p_{pred})\\mathbf{x}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "b_{new} = b_{old} + \\eta (y-p_{pred})\n",
    "$$\n",
    "\n",
    "Finally, the function should return the value of the loss for the current examples, that is:\n",
    "$$\n",
    "-y \\log_2(p_{pred}) - (1-y)\\log_2(1-p_{pred})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update(wb, x, y, eta):\n",
    "    #.............................\n",
    "    p_pred = predict_proba(wb, x)\n",
    "    wb['w'] += eta*(y-p_pred)*x\n",
    "    wb['b'] += eta*(y-p_pred)\n",
    "    \n",
    "    return -y*numpy.log2(p_pred)-(1-y)*numpy.log2(1-p_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual class: 1\n",
      "P(y=1): 0.5\n",
      "Loss: 1.0\n",
      "{'b': 0.050000000000000003,\n",
      " 'w': array([-0.00510916, -0.00941896,  0.05861284,  0.06567975])}\n",
      "P(y=1): 0.552\n",
      "\n",
      "Actual class: 0\n",
      "P(y=1): 0.48\n",
      "Loss: 0.943\n",
      "{'b': 0.0020289335835076,\n",
      " 'w': array([ 0.04832087, -0.00038221,  0.10706961,  0.12371601])}\n",
      "P(y=1): 0.423\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "wb = {'w':numpy.zeros((X_train.shape[1],)), 'b':0}\n",
    "eta = 0.1\n",
    "# Show P(y=1) before and after update\n",
    "\n",
    "# Process example 1\n",
    "i = 0\n",
    "print(\"Actual class: {}\".format(y_train[i]))\n",
    "print(\"P(y=1): {:.3}\".format(predict_proba(wb, X_train[i])))\n",
    "loss = update(wb, X_train[i], y_train[i], eta)\n",
    "print(\"Loss: {:.3}\".format(loss))\n",
    "pprint(wb)\n",
    "print(\"P(y=1): {:.3}\".format(predict_proba(wb, X_train[i])))\n",
    "\n",
    "\n",
    "print()\n",
    "# Process example 5\n",
    "i = 5\n",
    "print(\"Actual class: {}\".format(y_train[i]))\n",
    "print(\"P(y=1): {:.3}\".format(predict_proba(wb, X_train[i])))\n",
    "loss = update(wb, X_train[i], y_train[i], eta)\n",
    "print(\"Loss: {:.3}\".format(loss))\n",
    "pprint(wb)\n",
    "print(\"P(y=1): {:.3}\".format(predict_proba(wb, X_train[i])))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.5 \n",
    "\n",
    "Define function `fit`, which will use the `update` function on each training example in turn, for a single iteration of SGD. The function takes the following arguments:\n",
    "\n",
    "- `wb` - the current model weights and bias\n",
    "- `X` - the matrix of training example features\n",
    "- `y` - the vector of training example classes\n",
    "- `eta=0.1` - the learning rate, with default 0.1\n",
    "\n",
    "The function returns the sum of the losses on all the examples, as given by `update`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit(wb, X, y, eta=0.01):\n",
    "    #..................................\n",
    "    assert X.shape[0] == y.shape[0]\n",
    "    # Explicit for loop\n",
    "    loss = []\n",
    "    for i in range(X.shape[0]):\n",
    "        L = update(wb, X[i,:], y[i], eta)\n",
    "        loss.append(L)\n",
    "    return sum(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit(wb, X, y, eta=0.01):\n",
    "    #..................................\n",
    "    assert X.shape[0] == y.shape[0]\n",
    "    # List comprehension\n",
    "    return sum(update(wb, X[i,:], y[i], eta) for i in range(X.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss\n",
      "0 17.7\n",
      "1 4.63\n",
      "2 2.82\n",
      "3 2.05\n",
      "4 1.62\n",
      "5 1.34\n",
      "6 1.15\n",
      "7 1.0\n",
      "8 0.89\n",
      "9 0.801\n"
     ]
    }
   ],
   "source": [
    "wb = {'w':numpy.zeros((4,)), 'b':0}\n",
    "eta = 0.01\n",
    "J = 10\n",
    "\n",
    "# Let's run 10 epochs of SGD\n",
    "print(\"epoch loss\")\n",
    "for j in range(J):\n",
    "    loss = fit(wb, X_train, y_train, eta=0.1)\n",
    "    print(\"{} {:.3}\".format(j, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.6\n",
    "\n",
    "Train your model for one pass (epoch) and check classification accuracy on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = {'w':numpy.zeros((4,)), 'b':0}\n",
    "fit(model, X_train, y_train, eta=0.1)\n",
    "acc = accuracy_score(predict(model, X_val), y_val)\n",
    "print(\"Accuracy: {:.3}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD classifier \n",
    "\n",
    "SGD classifier is suitable to use on large datasets, as well as on sparse data such as character or word ngram counts.\n",
    "\n",
    "We'll use the scikit-learn implementation of Logistic Regression with SGD to learn to classify posts on various discussion groups into topics.  There are twenty groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism\n",
      "comp.graphics\n",
      "comp.os.ms-windows.misc\n",
      "comp.sys.ibm.pc.hardware\n",
      "comp.sys.mac.hardware\n",
      "comp.windows.x\n",
      "misc.forsale\n",
      "rec.autos\n",
      "rec.motorcycles\n",
      "rec.sport.baseball\n",
      "rec.sport.hockey\n",
      "sci.crypt\n",
      "sci.electronics\n",
      "sci.med\n",
      "sci.space\n",
      "soc.religion.christian\n",
      "talk.politics.guns\n",
      "talk.politics.mideast\n",
      "talk.politics.misc\n",
      "talk.religion.misc\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "data = fetch_20newsgroups(remove=('headers', 'footers', 'quotes'))\n",
    "for group in data.target_names:\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is in the form of raw text, so we'll need to extract some features from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n"
     ]
    }
   ],
   "source": [
    "print(data.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split the data into train and validation, and then extract word counts from the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_train, text_val, y_train, y_val = train_test_split(data.data, data.target, test_size=1/2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer(analyzer='word', ngram_range=(1,1), lowercase=True)\n",
    "X_train = vec.fit_transform(text_train)\n",
    "X_val = vec.transform(text_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now try the SGDClassifier on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.603\n"
     ]
    }
   ],
   "source": [
    "model = SGDClassifier(loss='log', random_state=666)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_val)\n",
    "print(\"{:.3}\".format(accuracy_score(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.7\n",
    "\n",
    "Experiment with different features and model hyperparameters, and find a well performing setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
